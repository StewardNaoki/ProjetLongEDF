{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten,Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste=[]# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfA1 = pd.read_csv('inputA1.csv',names=['a11', 'a12','a13','a14','a15','a16'])\n",
    "dfA2 = pd.read_csv('inputA2.csv',names=['a21', 'a22','a23','a24','a25','a26'])\n",
    "dfA3 = pd.read_csv('inputA3.csv',names=['a31', 'a32','a33','a34','a35','a36'])\n",
    "dfA4 = pd.read_csv('inputA4.csv',names=['a41', 'a42','a43','a44','a45','a46'])\n",
    "dfA5 = pd.read_csv('inputA5.csv',names=['a51', 'a52','a53','a54','a55','a56'])\n",
    "\n",
    "\n",
    "dfC = pd.read_csv('inputC.csv',names=['c1', 'c2','c3','c4','c5','c6'])\n",
    "dfB1 = pd.read_csv('inputB1.csv',names=['B1'])\n",
    "dfB2 = pd.read_csv('inputB2.csv',names=['B2'])\n",
    "dfB3 = pd.read_csv('inputB3.csv',names=['B3'])\n",
    "dfB4 = pd.read_csv('inputB4.csv',names=['B4'])\n",
    "dfB5 = pd.read_csv('inputB5.csv',names=['B5'])\n",
    "target= pd.read_csv('output.csv',names=['Var0', 'Var1','Var2','Var3','Var4','Var5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a11       a12       a13  a14       a15  a16       a21       a22  \\\n",
      "0    0.052556  0.166901  0.137718    0  0.043893    0  0.077723  0.087978   \n",
      "1    0.125884  0.187970  0.139366    0  0.037804    0  0.063357  0.084081   \n",
      "2    0.096723  0.192558  0.159630    0  0.038893    0  0.085472  0.087091   \n",
      "3    0.147678  0.154509  0.136953    0  0.046059    0  0.060279  0.103382   \n",
      "4    0.050547  0.205408  0.137091    0  0.042412    0  0.063953  0.086810   \n",
      "..        ...       ...       ...  ...       ...  ...       ...       ...   \n",
      "995  0.050216  0.183270  0.151542    0  0.048754    0  0.098030  0.101454   \n",
      "996  0.061725  0.223085  0.148519    0  0.044129    0  0.087420  0.091174   \n",
      "997  0.053334  0.176088  0.157776    0  0.038911    0  0.067271  0.084439   \n",
      "998  0.067554  0.187609  0.161419    0  0.039811    0  0.090817  0.111321   \n",
      "999  0.053606  0.157215  0.144050    0  0.039703    0  0.082437  0.104214   \n",
      "\n",
      "          a23       a24  ...        c3        c4        c5        c6  Var0  \\\n",
      "0    0.120643  0.011609  ...  0.007092  0.002858  0.004393  0.000551   0.0   \n",
      "1    0.120309  0.007401  ...  0.009941  0.002859  0.004231  0.000519   0.0   \n",
      "2    0.105592  0.008818  ...  0.007652  0.002734  0.006815  0.000747   0.0   \n",
      "3    0.090972  0.008804  ...  0.011923  0.002725  0.005651  0.001066   0.0   \n",
      "4    0.080370  0.011064  ...  0.011737  0.001347  0.006124  0.001370   0.0   \n",
      "..        ...       ...  ...       ...       ...       ...       ...   ...   \n",
      "995  0.129393  0.007555  ...  0.009182  0.002662  0.006380  0.001109   0.0   \n",
      "996  0.102111  0.011675  ...  0.010494  0.001618  0.005170  0.000849   0.0   \n",
      "997  0.087826  0.010277  ...  0.008831  0.002006  0.003084  0.000906   0.0   \n",
      "998  0.086333  0.010562  ...  0.010713  0.001562  0.006034  0.001453   0.0   \n",
      "999  0.106197  0.011107  ...  0.011140  0.002072  0.006531  0.000918   0.0   \n",
      "\n",
      "          Var1       Var2       Var3  Var4       Var5  \n",
      "0    48.334279   0.000000   0.000000   0.0  51.665721  \n",
      "1    45.514874   0.000000   0.000000   0.0  54.485126  \n",
      "2     0.000000  44.990136   0.000000   0.0  55.009864  \n",
      "3    56.481254   0.000000   0.000000   0.0  43.518746  \n",
      "4    41.938128   0.000000  58.061872   0.0   0.000000  \n",
      "..         ...        ...        ...   ...        ...  \n",
      "995  40.871915   0.000000   0.000000   0.0  59.128085  \n",
      "996  33.753631   0.000000   0.000000   0.0  66.246369  \n",
      "997  45.655803   0.000000   0.000000   0.0  54.344197  \n",
      "998  42.832359   0.000000   0.000000   0.0  57.167641  \n",
      "999  48.246621   0.000000   0.000000   0.0  51.753379  \n",
      "\n",
      "[1000 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.concat([dfA1,dfA2,dfA3,dfA4,dfA5,dfB1,dfB2,dfB3,dfB4,dfB5,dfC,target], axis=1, sort=False)\n",
    "train, validate, test = np.split(dataset.sample(frac=1), [int(.6*len(dataset)), int(.8*len(dataset))])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 34)                1428      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 100)               3500      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 35,834\n",
      "Trainable params: 35,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(34, kernel_initializer='normal',input_dim = train[['a11', 'a12','a13','a14','a15','a16',\n",
    "                                                                    'a21', 'a22','a23','a24','a25','a26',\n",
    "                                                                    'a31', 'a32','a33','a34','a35','a36',\n",
    "                                                                    'a41', 'a42','a43','a44','a45','a46',\n",
    "                                                                     'a51', 'a52','a53','a54','a55','a56', \n",
    "                                                                    'B1','B2','B3','B4','B5',\n",
    "                                                                    'c1', 'c2','c3','c4','c5','c6']].shape[1],\n",
    "                                                                    activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(100, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(100, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(100, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(100, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "#NN_model.add(Dense(30, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(6, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "#NN_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-6c921ec69501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtensorboard_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'log_dir' is not defined"
     ]
    }
   ],
   "source": [
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 2, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_54 to have shape (1,) but got array with shape (6,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7a2a9c544500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0;34m'B1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     'c1', 'c2','c3','c4','c5','c6']], train[['Var0', 'Var1','Var2','Var3','Var4','Var5']], epochs=500,\n\u001b[0;32m----> 8\u001b[0;31m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_54 to have shape (1,) but got array with shape (6,)"
     ]
    }
   ],
   "source": [
    "NN_model.fit(train[['a11', 'a12','a13','a14','a15','a16',\n",
    "                    'a21', 'a22','a23','a24','a25','a26',\n",
    "                    'a31', 'a32','a33','a34','a35','a36',\n",
    "                    'a41', 'a42','a43','a44','a45','a46',\n",
    "                    'a51', 'a52','a53','a54','a55','a56',\n",
    "                    'B1','B2','B3','B4','B5',\n",
    "                    'c1', 'c2','c3','c4','c5','c6']], train[['Var0', 'Var1','Var2','Var3','Var4','Var5']], epochs=500,\n",
    "                     batch_size=32, validation_split = 0.2, callbacks=callbacks_list,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorboard_callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-6056b61c55cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0;34m'B1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     'c1', 'c2','c3','c4','c5','c6']], train[['Var0', 'Var1','Var2','Var3','Var4','Var5']], epochs=500,\n\u001b[0;32m----> 8\u001b[0;31m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensorboard_callback' is not defined"
     ]
    }
   ],
   "source": [
    "NN_model.fit(train[['a11', 'a12','a13','a14','a15','a16',\n",
    "                    'a21', 'a22','a23','a24','a25','a26',\n",
    "                    'a31', 'a32','a33','a34','a35','a36',\n",
    "                    'a41', 'a42','a43','a44','a45','a46',\n",
    "                    'a51', 'a52','a53','a54','a55','a56',\n",
    "                    'B1','B2','B3','B4','B5',\n",
    "                    'c1', 'c2','c3','c4','c5','c6']], train[['Var0', 'Var1','Var2','Var3','Var4','Var5']], epochs=500,\n",
    "                     batch_size=32, validation_split = 0.2, callbacks=tensorboard_callback,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.callbacks.callbacks.ModelCheckpoint object at 0x1a3ea624d0>]\n"
     ]
    }
   ],
   "source": [
    "print(callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load wights file of the best model :\n",
    "wights_file = 'Weights-440--2.36772.hdf5' # choose the best checkpoint \n",
    "NN_model.load_weights(wights_file) # load it\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42.6442   32.96847  35.917534 47.18555  40.56782  41.821613 41.33475\n",
      " 32.5661   39.50702  46.880505 30.403475 47.517    39.152466 35.184372\n",
      " 42.08583  54.3192   40.26273  52.340786 31.619648 32.342827 33.65508\n",
      " 45.7053   32.490463 34.612434 41.947445 46.502495 34.737118 32.905144\n",
      " 43.763878 35.51286  46.074055 30.911795 30.471163 44.47991  46.786884\n",
      " 45.859932 30.585304 37.08292  42.090416 45.23929  36.984566 40.674244\n",
      " 39.895752 32.123974 43.06127  51.572483 48.176598 47.900616 50.87483\n",
      " 52.34889  49.884785 32.141228 44.07617  51.092487 45.491055 39.878517\n",
      " 40.344135 33.7612   30.688168 45.76426  33.873528 47.996845 43.432804\n",
      " 52.75432  48.156498 43.092556 44.86119  35.049564 29.776087 43.300247\n",
      " 36.972076 50.454826 49.34616  49.591846 42.02649  46.284218 39.39887\n",
      " 47.760704 54.92978  49.620613 29.741793 41.67679  36.332798 46.32105\n",
      " 42.139576 39.919437 38.43899  30.474915 53.93048  46.806232 35.026093\n",
      " 32.03535  42.457027 38.5967   49.59769  35.466297 46.8607   32.579983\n",
      " 37.353638 33.397045 40.020336 43.026634 43.652462 52.146194 31.0084\n",
      " 42.532253 32.71339  37.662148 38.230156 33.774227 47.20886  34.200905\n",
      " 48.90171  43.898365 38.321774 32.11729  44.067345 46.737427 34.38396\n",
      " 39.975273 34.464645 45.718014 51.83084  38.649467 29.397623 38.246677\n",
      " 33.852146 36.146004 34.880898 31.123186 45.7425   33.20889  46.02275\n",
      " 30.53075  49.520103 36.562    29.870796 39.688545 38.26192  42.153473\n",
      " 53.82335  48.4964   37.739475 44.51506  42.949825 40.535267 34.845154\n",
      " 46.65727  32.375526 36.684036 39.417305 32.456028 40.25769  39.94266\n",
      " 35.59988  51.265556 37.192635 37.08166  40.094368 37.63082  43.56684\n",
      " 32.056263 45.866524 44.732895 36.90616  46.260807 45.08498  41.47567\n",
      " 50.44363  40.640465 42.41587  34.342934 34.64621  46.100754 45.596813\n",
      " 42.856163 35.5411   30.669285 48.42696  39.085842 49.669716 38.65399\n",
      " 35.744385 38.640514 44.27466  45.277096 35.246723 40.139336 37.20316\n",
      " 35.386467 39.35907  44.730934 41.069855 44.67868  41.895412 33.59956\n",
      " 35.39425  43.586647 34.89235  36.677002]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = NN_model.predict(test[['a11', 'a12','a13','a14','a15','a16',\n",
    "                                    'a21', 'a22','a23','a24','a25','a26',\n",
    "                                    'a31', 'a32','a33','a34','a35','a36',\n",
    "                                     'a41', 'a42','a43','a44','a45','a46',\n",
    "                                     'a51', 'a52','a53','a54','a55','a56',\n",
    "                                     'B1','B2','B3','B4','B5',\n",
    "                                    'c1', 'c2','c3','c4','c5','c6']])\n",
    "print(predictions[:,1][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.6442\n"
     ]
    }
   ],
   "source": [
    "print(predictions[:,1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Var0       Var1       Var2  Var3  Var4       Var5\n",
      "597   0.0  42.117838   0.000000   0.0   0.0  57.882162\n",
      "867   0.0  32.969476   0.000000   0.0   0.0  67.030524\n",
      "276   0.0  36.332911   0.000000   0.0   0.0  63.667089\n",
      "793   0.0   0.000000  51.914611   0.0   0.0  48.085389\n",
      "994   0.0  41.105931   0.000000   0.0   0.0  58.894069\n",
      "..    ...        ...        ...   ...   ...        ...\n",
      "431   0.0  33.922109   0.000000   0.0   0.0  66.077891\n",
      "249   0.0   0.000000  43.758308   0.0   0.0  56.241692\n",
      "729   0.0  44.276443   0.000000   0.0   0.0  55.723557\n",
      "367   0.0  35.106070   0.000000   0.0   0.0  64.893930\n",
      "78    0.0  37.395506   0.000000   0.0   0.0  62.604494\n",
      "\n",
      "[200 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test[['Var0', 'Var1','Var2','Var3','Var4','Var5']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.layers import Input, Dense\n",
    "#from keras.models import Model\n",
    "\n",
    "# This returns a tensor\n",
    "#inputs = Input(shape=(4,))\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "#output_1 = Dense(64, activation='relu')(inputs)\n",
    "#output_2 = Dense(64, activation='relu')(output_1)\n",
    "#predictions = Dense(1, activation='softmax')(output_2)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "#model = Model(inputs=inputs, outputs=predictions)\n",
    "#model.compile(optimizer='rmsprop',\n",
    "#              loss='mean_absolute_error',\n",
    "#              metrics=['accuracy'])\n",
    "#model.fit(train, target)  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3c502390>,\n",
       " <matplotlib.lines.Line2D at 0x1a3ca135d0>,\n",
       " <matplotlib.lines.Line2D at 0x1a3c502890>,\n",
       " <matplotlib.lines.Line2D at 0x1a3c502a50>,\n",
       " <matplotlib.lines.Line2D at 0x1a3c502c10>,\n",
       " <matplotlib.lines.Line2D at 0x1a3c502b90>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(test[['Var0', 'Var1','Var2','Var3','Var4','Var5']],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a11</th>\n",
       "      <th>a12</th>\n",
       "      <th>a13</th>\n",
       "      <th>a14</th>\n",
       "      <th>a15</th>\n",
       "      <th>a16</th>\n",
       "      <th>a21</th>\n",
       "      <th>a22</th>\n",
       "      <th>a23</th>\n",
       "      <th>a24</th>\n",
       "      <th>...</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>Var0</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>597</td>\n",
       "      <td>0.112243</td>\n",
       "      <td>0.208630</td>\n",
       "      <td>0.156719</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074336</td>\n",
       "      <td>0.103889</td>\n",
       "      <td>0.086011</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.117838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.882162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>867</td>\n",
       "      <td>0.112405</td>\n",
       "      <td>0.214014</td>\n",
       "      <td>0.159289</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080864</td>\n",
       "      <td>0.096128</td>\n",
       "      <td>0.100536</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011759</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.969476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.030524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>0.079173</td>\n",
       "      <td>0.229041</td>\n",
       "      <td>0.151755</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047436</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094500</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.103177</td>\n",
       "      <td>0.011344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.332911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.667089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>793</td>\n",
       "      <td>0.142827</td>\n",
       "      <td>0.165241</td>\n",
       "      <td>0.153835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084573</td>\n",
       "      <td>0.115218</td>\n",
       "      <td>0.085763</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.006824</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.914611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.085389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>994</td>\n",
       "      <td>0.140259</td>\n",
       "      <td>0.188565</td>\n",
       "      <td>0.148177</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033896</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096316</td>\n",
       "      <td>0.090517</td>\n",
       "      <td>0.113587</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.105931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.894069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.064670</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.163922</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030103</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094997</td>\n",
       "      <td>0.096454</td>\n",
       "      <td>0.115522</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.304536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.695464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.122693</td>\n",
       "      <td>0.212865</td>\n",
       "      <td>0.135190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081141</td>\n",
       "      <td>0.110973</td>\n",
       "      <td>0.129417</td>\n",
       "      <td>0.011459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.351460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.648540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>0.070587</td>\n",
       "      <td>0.224920</td>\n",
       "      <td>0.141585</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031257</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080748</td>\n",
       "      <td>0.110164</td>\n",
       "      <td>0.127424</td>\n",
       "      <td>0.007846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007550</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.922151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.077849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>0.060634</td>\n",
       "      <td>0.207915</td>\n",
       "      <td>0.161348</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044653</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084666</td>\n",
       "      <td>0.086755</td>\n",
       "      <td>0.084581</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010220</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.896269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.103731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745</td>\n",
       "      <td>0.071131</td>\n",
       "      <td>0.188064</td>\n",
       "      <td>0.150214</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035669</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082040</td>\n",
       "      <td>0.084891</td>\n",
       "      <td>0.121864</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.814043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.185957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          a11       a12       a13  a14       a15  a16       a21       a22  \\\n",
       "597  0.112243  0.208630  0.156719    0  0.048084    0  0.074336  0.103889   \n",
       "867  0.112405  0.214014  0.159289    0  0.033054    0  0.080864  0.096128   \n",
       "276  0.079173  0.229041  0.151755    0  0.047436    0  0.094500  0.086914   \n",
       "793  0.142827  0.165241  0.153835    0  0.031831    0  0.084573  0.115218   \n",
       "994  0.140259  0.188565  0.148177    0  0.033896    0  0.096316  0.090517   \n",
       "221  0.064670  0.192500  0.163922    0  0.030103    0  0.094997  0.096454   \n",
       "188  0.122693  0.212865  0.135190    0  0.039556    0  0.081141  0.110973   \n",
       "885  0.070587  0.224920  0.141585    0  0.031257    0  0.080748  0.110164   \n",
       "499  0.060634  0.207915  0.161348    0  0.044653    0  0.084666  0.086755   \n",
       "745  0.071131  0.188064  0.150214    0  0.035669    0  0.082040  0.084891   \n",
       "\n",
       "          a23       a24  ...        c3        c4        c5        c6  Var0  \\\n",
       "597  0.086011  0.011157  ...  0.010388  0.001966  0.004089  0.000681   0.0   \n",
       "867  0.100536  0.011864  ...  0.011759  0.001692  0.006498  0.001187   0.0   \n",
       "276  0.103177  0.011344  ...  0.010736  0.001200  0.005504  0.000941   0.0   \n",
       "793  0.085763  0.007570  ...  0.007857  0.001238  0.006824  0.001231   0.0   \n",
       "994  0.113587  0.007039  ...  0.009447  0.001900  0.003007  0.001155   0.0   \n",
       "221  0.115522  0.011270  ...  0.008419  0.002586  0.004777  0.001159   0.0   \n",
       "188  0.129417  0.011459  ...  0.009978  0.002100  0.005604  0.000550   0.0   \n",
       "885  0.127424  0.007846  ...  0.007550  0.002245  0.004898  0.001162   0.0   \n",
       "499  0.084581  0.008236  ...  0.010220  0.002913  0.006660  0.001494   0.0   \n",
       "745  0.121864  0.008592  ...  0.010130  0.002110  0.005194  0.001107   0.0   \n",
       "\n",
       "          Var1       Var2  Var3  Var4       Var5  \n",
       "597  42.117838   0.000000   0.0   0.0  57.882162  \n",
       "867  32.969476   0.000000   0.0   0.0  67.030524  \n",
       "276  36.332911   0.000000   0.0   0.0  63.667089  \n",
       "793   0.000000  51.914611   0.0   0.0  48.085389  \n",
       "994  41.105931   0.000000   0.0   0.0  58.894069  \n",
       "221  42.304536   0.000000   0.0   0.0  57.695464  \n",
       "188  41.351460   0.000000   0.0   0.0  58.648540  \n",
       "885  32.922151   0.000000   0.0   0.0  67.077849  \n",
       "499  39.896269   0.000000   0.0   0.0  60.103731  \n",
       "745  46.814043   0.000000   0.0   0.0  53.185957  \n",
       "\n",
       "[10 rows x 47 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42.6442   32.96847  35.917534 47.18555  40.56782  41.821613 41.33475\n",
      " 32.5661   39.50702  46.880505 30.403475 47.517    39.152466 35.184372\n",
      " 42.08583  54.3192   40.26273  52.340786 31.619648 32.342827 33.65508\n",
      " 45.7053   32.490463 34.612434 41.947445 46.502495 34.737118 32.905144\n",
      " 43.763878 35.51286  46.074055 30.911795 30.471163 44.47991  46.786884\n",
      " 45.859932 30.585304 37.08292  42.090416 45.23929  36.984566 40.674244\n",
      " 39.895752 32.123974 43.06127  51.572483 48.176598 47.900616 50.87483\n",
      " 52.34889  49.884785 32.141228 44.07617  51.092487 45.491055 39.878517\n",
      " 40.344135 33.7612   30.688168 45.76426  33.873528 47.996845 43.432804\n",
      " 52.75432  48.156498 43.092556 44.86119  35.049564 29.776087 43.300247\n",
      " 36.972076 50.454826 49.34616  49.591846 42.02649  46.284218 39.39887\n",
      " 47.760704 54.92978  49.620613 29.741793 41.67679  36.332798 46.32105\n",
      " 42.139576 39.919437 38.43899  30.474915 53.93048  46.806232 35.026093\n",
      " 32.03535  42.457027 38.5967   49.59769  35.466297 46.8607   32.579983\n",
      " 37.353638 33.397045 40.020336 43.026634 43.652462 52.146194 31.0084\n",
      " 42.532253 32.71339  37.662148 38.230156 33.774227 47.20886  34.200905\n",
      " 48.90171  43.898365 38.321774 32.11729  44.067345 46.737427 34.38396\n",
      " 39.975273 34.464645 45.718014 51.83084  38.649467 29.397623 38.246677\n",
      " 33.852146 36.146004 34.880898 31.123186 45.7425   33.20889  46.02275\n",
      " 30.53075  49.520103 36.562    29.870796 39.688545 38.26192  42.153473\n",
      " 53.82335  48.4964   37.739475 44.51506  42.949825 40.535267 34.845154\n",
      " 46.65727  32.375526 36.684036 39.417305 32.456028 40.25769  39.94266\n",
      " 35.59988  51.265556 37.192635 37.08166  40.094368 37.63082  43.56684\n",
      " 32.056263 45.866524 44.732895 36.90616  46.260807 45.08498  41.47567\n",
      " 50.44363  40.640465 42.41587  34.342934 34.64621  46.100754 45.596813\n",
      " 42.856163 35.5411   30.669285 48.42696  39.085842 49.669716 38.65399\n",
      " 35.744385 38.640514 44.27466  45.277096 35.246723 40.139336 37.20316\n",
      " 35.386467 39.35907  44.730934 41.069855 44.67868  41.895412 33.59956\n",
      " 35.39425  43.586647 34.89235  36.677002]\n",
      "48.334278999999995\n",
      "-0.043517451733350754\n"
     ]
    }
   ],
   "source": [
    "print(predictions[:,1][:])\n",
    "print(test['Var1'][0])\n",
    "print((predictions[:,0][0]-test['Var0'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=test['Var1'].to_numpy()\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+000  6.17582057e-322  0.00000000e+000  6.92640531e-310\n",
      "  0.00000000e+000              nan              nan  0.00000000e+000\n",
      "  1.88492663e-240  0.00000000e+000  4.44659081e-323  5.57022207e-313\n",
      "  6.92640531e-310              nan  0.00000000e+000              nan\n",
      "  0.00000000e+000 -6.32744249e+304  3.55727265e-322  5.43472210e-323\n",
      "  5.57022207e-313  6.92640531e-310  2.47032823e-323  4.94065646e-323\n",
      "              nan  0.00000000e+000  2.12199579e-314  7.11454530e-322\n",
      "  5.43472210e-323  5.57022207e-313  6.92640531e-310  0.00000000e+000\n",
      "  1.28457068e-322              nan  0.00000000e+000  4.94065646e-324\n",
      "  1.06718180e-321  5.43472210e-323  5.57022207e-313  6.92640531e-310\n",
      "              nan  1.28457068e-322              nan  0.00000000e+000\n",
      "  2.12199579e-314  1.42290906e-321  5.43472210e-323  5.57022207e-313\n",
      "  6.92640531e-310  0.00000000e+000  9.88131292e-323              nan\n",
      "  5.56933614e-313  2.12199579e-314  1.77863633e-321  3.45845952e-323\n",
      "  5.57022207e-313  6.92640531e-310  0.00000000e+000  1.28457068e-322\n",
      "              nan  5.56933614e-313  4.94065646e-324  5.57022207e-313\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  5.57022207e-313  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  5.57022207e-313  0.00000000e+000  2.13436359e-321\n",
      "  9.88131292e-324  5.57022207e-313  6.92640531e-310  0.00000000e+000\n",
      "  1.28457068e-322              nan  0.00000000e+000  4.94065646e-324\n",
      "  3.59679790e-321  4.44659081e-323  5.57022207e-313  6.92640531e-310\n",
      "  4.94065646e-324  1.28457068e-322              nan  5.56933614e-313\n",
      "  4.94065646e-324  5.57022207e-313  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  5.57022207e-313\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  5.57022207e-313\n",
      "  5.57022207e-313  3.95252517e-321  9.88131292e-324  5.57022207e-313\n",
      "  6.92640531e-310  0.00000000e+000  1.28457068e-322              nan\n",
      "  5.57022207e-313  4.94065646e-324  5.41495948e-321  4.44659081e-323\n",
      "  5.57022207e-313  6.92640531e-310  9.88131292e-324  1.28457068e-322\n",
      "              nan  5.56933614e-313  5.51718906e-313  5.77068674e-321\n",
      "  1.48219694e-323  5.57022207e-313  6.92640531e-310  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  4.94065646e-324\n",
      "  0.00000000e+000  5.57022207e-313  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000\n",
      "  0.00000000e+000  5.57022207e-313  5.57022207e-313  5.77068674e-321\n",
      "  9.88131292e-324  5.57022207e-313  6.92640531e-310              nan\n",
      "  1.28457068e-322              nan  2.24657261e-314  2.12199579e-314\n",
      "  7.23312106e-321  4.44659081e-323  5.57022207e-313  6.92640531e-310\n",
      "  2.24657267e-314  2.24658086e-314  8.84055836e-291  2.24657270e-314]\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    a[i]="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([15., 26., 26., 23., 28., 22., 29., 15., 11.,  5.]),\n",
       " array([29.397623, 31.950838, 34.504055, 37.05727 , 39.610485, 42.1637  ,\n",
       "        44.716915, 47.270134, 49.82335 , 52.376564, 54.92978 ],\n",
       "       dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(a)\n",
    "plt.hist(predictions[:,1][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27705629323670583\n",
      "1.0089658076196094e-06\n",
      "0.1725381563789038\n",
      "2226.47619388999\n",
      "0.28956183110001155\n",
      "0.23321432280962778\n",
      "0.00027918636506878847\n",
      "0.12677154964883328\n",
      "0.1515155290488329\n",
      "0.004417145358455557\n",
      "0.009563899629315854\n",
      "1.9078590460766798\n",
      "0.00036669108270426747\n",
      "0.1252487856597005\n",
      "1771.2171447391156\n",
      "9.317276351906777\n",
      "0.3184157049835437\n",
      "2.2823958373517357\n",
      "0.06397359515058364\n",
      "0.0003817004934161475\n",
      "0.1642422426531201\n",
      "4.919171887970703\n",
      "0.008643373143991639\n",
      "0.03745796880027653\n",
      "0.12949999994212064\n",
      "2162.482023741177\n",
      "0.16600835807640307\n",
      "0.16537500882886605\n",
      "1915.2770061023184\n",
      "0.2200038269599123\n",
      "352.6898918103177\n",
      "0.00014894585440978358\n",
      "0.00016995805048032747\n",
      "3.368051519302016\n",
      "0.021073547271705656\n",
      "3.7756183896534656\n",
      "0.09963950595100513\n",
      "0.004799569523575788\n",
      "1.9139450957617212\n",
      "0.1402489992313048\n",
      "0.025497148357072404\n",
      "0.18688582069445855\n",
      "0.0778181498334096\n",
      "0.05851084639143567\n",
      "0.014534151188331314\n",
      "7.373043821482328\n",
      "0.6118421664574928\n",
      "0.5347006880602012\n",
      "5.970715030170877\n",
      "0.5208633073312824\n",
      "0.6549248950904462\n",
      "0.04974874987361222\n",
      "0.006878193491265527\n",
      "0.1872515009722078\n",
      "0.009770637464130132\n",
      "0.004543319555706512\n",
      "0.15071920623462867\n",
      "0.24677551373721515\n",
      "0.001981712359966596\n",
      "4.589237897216003\n",
      "0.1611825555366294\n",
      "2303.6971535071643\n",
      "0.0660829837105542\n",
      "3.2462481551047544\n",
      "0.0021858388313654143\n",
      "0.018559975158478285\n",
      "0.03166399449874678\n",
      "0.05875806951017549\n",
      "0.2757812697571218\n",
      "0.05824393738546953\n",
      "0.09846641334976072\n",
      "2545.6895025112317\n",
      "2.3092209688951133\n",
      "4.632845277706292\n",
      "1.005408778383363\n",
      "0.6075363249552838\n",
      "0.4159610690358608\n",
      "2281.084850446845\n",
      "13.71478601851653\n",
      "4.312939996998348\n",
      "0.26915725717066075\n",
      "0.045615275923299864\n",
      "0.1583164487972027\n",
      "4.491730313501738\n",
      "0.2410800589975006\n",
      "0.37646150800727785\n",
      "0.053158122657785065\n",
      "0.03319485433438048\n",
      "7.4307327622292245\n",
      "2.320621264568596\n",
      "0.10084719305295614\n",
      "0.156790023823856\n",
      "0.04425703672343382\n",
      "0.31677787794818607\n",
      "0.021850284618608745\n",
      "0.06249442529521164\n",
      "2.5271502233769403\n",
      "0.06132767080954103\n",
      "0.06271433578865333\n",
      "0.009869600793639553\n",
      "0.09033099444139182\n",
      "0.10812076174093216\n",
      "0.17615563996747494\n",
      "7.076938266671779\n",
      "0.030717132005646585\n",
      "1.405108519978466\n",
      "0.11486449541554052\n",
      "0.131106617570246\n",
      "0.2186283025268551\n",
      "0.20443045089024145\n",
      "0.050987676740750554\n",
      "0.18671918502448684\n",
      "4.179045923788717\n",
      "0.06434744369578904\n",
      "0.10761317491906892\n",
      "0.07054097130615851\n",
      "0.00015115880042922096\n",
      "1.5037558747069804\n",
      "0.04319217670072562\n",
      "0.8079796232426243\n",
      "0.06568282864773159\n",
      "0.7520986900240302\n",
      "6.852384364997329\n",
      "0.0018622218230147634\n",
      "1.542559186344086\n",
      "0.0029981758757354417\n",
      "0.27037280605484987\n",
      "0.3963045923050631\n",
      "0.07155115583529531\n",
      "0.09761555958312959\n",
      "0.0221290333587712\n",
      "0.0061559704123729415\n",
      "0.9196160682301037\n",
      "0.005729691444570186\n",
      "0.004734478305370159\n",
      "0.008844786547514218\n",
      "0.37751710198581623\n",
      "0.3969816181115501\n",
      "0.8242589337705329\n",
      "0.4564408994090013\n",
      "6.138377885464023\n",
      "2.398874598804456\n",
      "0.0027414386759968593\n",
      "0.17846448848285093\n",
      "0.0011819353653618795\n",
      "1643.1078607264353\n",
      "0.06870647050346596\n",
      "2.8123641360438087\n",
      "0.09114274764119967\n",
      "0.8237500037822112\n",
      "0.0018123758076132293\n",
      "1.5225483968011524e-05\n",
      "0.3306923592898562\n",
      "1.0225551990227715\n",
      "0.10949334179774646\n",
      "0.07213772203185473\n",
      "0.029769505506664053\n",
      "0.1738045891257647\n",
      "0.5456008960361028\n",
      "0.6155073610545453\n",
      "0.026002892986991315\n",
      "0.0030483682599558317\n",
      "0.20305725125069998\n",
      "0.19046512442981842\n",
      "0.13025859254734767\n",
      "3.2767804601102424\n",
      "0.39550639163054985\n",
      "1720.2311904053786\n",
      "2544.5598296213575\n",
      "0.2611110021611297\n",
      "2.1564168681368066\n",
      "0.0038577334378410958\n",
      "0.1689154788380851\n",
      "0.0040511677275528405\n",
      "3.7888731429943907\n",
      "0.0629422671938532\n",
      "0.19494030923419214\n",
      "0.032959611148866474\n",
      "0.19833841151499693\n",
      "0.27011289837809743\n",
      "5.528889704869542\n",
      "0.7762372978515212\n",
      "0.2739195424601493\n",
      "0.3269994144379813\n",
      "0.24498956237516703\n",
      "1.3325521010764827\n",
      "0.1902275421055862\n",
      "0.032442626374188044\n",
      "0.38610772044020086\n",
      "0.2742030597022158\n",
      "0.34169890800589353\n",
      "0.05510481270397874\n",
      "1.3578394250016334e-06\n",
      "0.0066433225960321205\n",
      "0.07578544021668085\n",
      "0.10403799678379717\n",
      "1252.7528596125194\n",
      "0.4758184751356072\n",
      "0.045676561902527016\n",
      "0.5162480653757485\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    erreur=(a[i]-predictions[:,1][i])*(a[i]-predictions[:,1][i])\n",
    "    print(erreur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
